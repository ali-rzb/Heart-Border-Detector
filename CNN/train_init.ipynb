{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import cv2 as cv\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_device = tf.config.experimental.list_physical_devices()\n",
    "# print('Num GPUs Available: ',len(physical_device))\n",
    "# tf.config.experimental.set_memory_growth(physical_device[2],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_classes(_path):\n",
    "    _C0 = list(os.scandir(_path+'/C0'))\n",
    "    _C1 = list(os.scandir(_path+'/C1'))\n",
    "    while True:\n",
    "        _C0 = list(os.scandir(_path+'/C0'))\n",
    "        if len(_C1)==len(_C0):\n",
    "            break\n",
    "        else:\n",
    "            for c in random.sample(_C0,1):\n",
    "                os.remove(c)\n",
    "def read_from_path(_path):\n",
    "    \n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    \n",
    "    for p in _path:\n",
    "        _C0 = os.listdir(p+'/C0')\n",
    "        _C1 = os.listdir(p+'/C1')\n",
    "        temp_data_x = []\n",
    "        temp_data_y = []\n",
    "\n",
    "        for f in _C0:\n",
    "            full_name = p+'/C0/'+f\n",
    "            img = (np.array(cv.imread(full_name,0) ,dtype=np.uint8).astype('float32')/255)\n",
    "            temp_data_x.append(img)\n",
    "            temp_data_y.append(0)\n",
    "\n",
    "        for f in _C1:\n",
    "            full_name = p+'/C1/'+f\n",
    "            img = (np.array(cv.imread(full_name,0) ,dtype=np.uint8).astype('float32')/255)\n",
    "            temp_data_x.append(img)\n",
    "            temp_data_y.append(1)\n",
    "        \n",
    "        data_x += temp_data_x\n",
    "        data_y += temp_data_y\n",
    "\n",
    "    data_x,data_y = shuffle(data_x,data_y)\n",
    "\n",
    "    return np.array(data_x),np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    equalize_classes('labeling/data/frame_1_{:02d}_data_16'.format(i))\n",
    "\n",
    "\n",
    "train_path = ['labeling/data/frame_1_01_data_16',\\\n",
    "            #   'labeling/data/frame_1_02_data_16',\\\n",
    "              'labeling/data/frame_1_03_data_16']\n",
    "\n",
    "valid_path = ['labeling/data/frame_1_02_data_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x,train_data_y = read_from_path(train_path)\n",
    "valid_data_x,valid_data_y = read_from_path(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 16, 16, 1)\n",
      "(42, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "shape = np.shape(train_data_x)\n",
    "train_data_x = np.reshape(train_data_x,(shape[0],16,16,1))\n",
    "print(train_data_x.shape)\n",
    "\n",
    "shape = np.shape(valid_data_x)\n",
    "valid_data_x = np.reshape(valid_data_x,(shape[0],16,16,1))\n",
    "print(valid_data_x.shape)\n",
    "\n",
    "# shape = np.shape(test_data_x)\n",
    "# test_data_x = np.reshape(test_data_x,(shape[0],16,16,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (104,) (42,)\n",
      "Shape after one-hot encoding:  (104, 2) (42, 2)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "print(\"Shape before one-hot encoding: \", train_data_y.shape,valid_data_y.shape,)\n",
    "\n",
    "if train_data_y.shape==(train_data_y.shape[0],):\n",
    "    train_data_y = np_utils.to_categorical(train_data_y, n_classes)\n",
    "\n",
    "if valid_data_y.shape==(valid_data_y.shape[0],):\n",
    "    valid_data_y = np_utils.to_categorical(valid_data_y, n_classes)\n",
    "\n",
    "print(\"Shape after one-hot encoding: \", train_data_y.shape,valid_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images,labels):\n",
    "    fig, axes=plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img,ax in zip(images,axes):\n",
    "        ax.imshow(img,cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "plotImages(train_data_x[0:10],train_data_y[0:10])\n",
    "print(train_data_y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('models/_vn_32_64_8_100_94.h5')\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(16,16,1)))\n",
    "# model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(16,16,8)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# # compiling the sequential model\n",
    "# model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               921700    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 940,718\n",
      "Trainable params: 940,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7081 - accuracy: 0.4808 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5a4a9ae80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_x, train_data_y, batch_size=5, epochs=5, validation_data=(valid_data_x, valid_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isfile('models/_vn1.h5') is False:\n",
    "model.save('models/_vn_32_128_8_200_94_retrain.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95f40879b6b7329d00907e385be3c1da0f6b0e05175b381c46c80fa0aa2d3201"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
